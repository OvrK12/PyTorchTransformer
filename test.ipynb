{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, DefaultDataCollator, DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "from transformer.transformer import Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oliver/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmt14 =  load_dataset(\"wmt/wmt14\", \"de-en\")\n",
    "train_subset = wmt14['train'].select(range(10000))\n",
    "de_tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-german-cased\")\n",
    "en_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "special_tokens_dict = {'bos_token': '<s>', 'eos_token': '</s>'}\n",
    "en_tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30524"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tokenizer.convert_tokens_to_ids(\"lol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    de_texts = [translation['de'] for translation in examples['translation']]\n",
    "    en_texts = [translation['en'] for translation in examples['translation']]\n",
    "    \n",
    "    de_inputs = de_tokenizer(de_texts, truncation=True, max_length=128, padding=\"max_length\")\n",
    "    en_inputs = en_tokenizer(en_texts, truncation=True, max_length=128, padding=\"max_length\")\n",
    "    \n",
    "    model_inputs = {\n",
    "        \"input_ids\": de_inputs[\"input_ids\"],\n",
    "        \"attention_mask\": de_inputs[\"attention_mask\"],\n",
    "        \"decoder_input_ids\": en_inputs[\"input_ids\"],\n",
    "        \"decoder_attention_mask\": en_inputs[\"attention_mask\"],\n",
    "        \"labels\": en_inputs[\"input_ids\"].copy()\n",
    "    }\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<s>',\n",
       " 'eos_token': '</s>',\n",
       " 'unk_token': '[UNK]',\n",
       " 'sep_token': '[SEP]',\n",
       " 'pad_token': '[PAD]',\n",
       " 'cls_token': '[CLS]',\n",
       " 'mask_token': '[MASK]'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4428318590f2449687b103783c5651f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = train_subset.map(preprocess_function, batched=True, batch_size=1000)\n",
    "#tokenized_dataset.set_format(\"torch\")\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"])\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_dataset, shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, Loss: 10.600179672241211\n",
      "Batch 10, Loss: 8.862262725830078\n",
      "Batch 20, Loss: 7.864902973175049\n",
      "Batch 30, Loss: 7.641119956970215\n",
      "Batch 40, Loss: 6.921629428863525\n",
      "Batch 50, Loss: 7.2100830078125\n",
      "Batch 60, Loss: 6.524007320404053\n",
      "Batch 70, Loss: 6.3765363693237305\n",
      "Batch 80, Loss: 6.521219253540039\n",
      "Batch 90, Loss: 6.109145164489746\n",
      "Batch 100, Loss: 6.268571853637695\n",
      "Batch 110, Loss: 5.916914939880371\n",
      "Batch 120, Loss: 6.040268421173096\n",
      "Batch 130, Loss: 6.002480506896973\n",
      "Batch 140, Loss: 5.708379745483398\n",
      "Batch 150, Loss: 5.76394510269165\n",
      "Batch 160, Loss: 5.843137741088867\n",
      "Batch 170, Loss: 6.137154579162598\n",
      "Batch 180, Loss: 5.7472100257873535\n",
      "Batch 190, Loss: 5.356274604797363\n",
      "Batch 200, Loss: 5.383860111236572\n",
      "Batch 210, Loss: 5.734013557434082\n",
      "Batch 220, Loss: 5.699577808380127\n",
      "Batch 230, Loss: 5.559024333953857\n",
      "Batch 240, Loss: 5.112642765045166\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m decoder_in \u001b[38;5;241m=\u001b[39m decoder_in[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Forward pass - shape: batch_size x seq_length x vocab_size\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Reshape for loss calculation. Loss_fn expects batch to be flattened\u001b[39;00m\n\u001b[1;32m     37\u001b[0m batch_size, seq_len, vocab_size \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Repos/PyTorchTransformer/transformer/transformer.py:47\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt)\u001b[0m\n\u001b[1;32m     44\u001b[0m src_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_src_mask(src)\n\u001b[1;32m     45\u001b[0m tgt_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_tgt_mask(tgt)\n\u001b[0;32m---> 47\u001b[0m encoder_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m decoder_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(tgt, encoder_out, src_mask, tgt_mask)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# dimensions are batch_size x seq_length x vocab_size\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Repos/PyTorchTransformer/transformer/encoder.py:37\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, input, mask)\u001b[0m\n\u001b[1;32m     34\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(\u001b[38;5;28minput\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding(positions))\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_blocks:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# query, key, value all come from the encoder out\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Repos/PyTorchTransformer/transformer/transformer_block.py:27\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, query, key_value, mask)\u001b[0m\n\u001b[1;32m     24\u001b[0m attention \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmha(query, key_value, mask)\n\u001b[1;32m     25\u001b[0m residual_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_1(query \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention))\n\u001b[0;32m---> 27\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresidual_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_2(residual_1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(out))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Transformer(\n",
    "    len(de_tokenizer),\n",
    "    len(en_tokenizer),\n",
    "    de_tokenizer.pad_token_id,\n",
    "    en_tokenizer.pad_token_id,\n",
    "    forward_dim=2048,\n",
    "    emb_dim=512,\n",
    "    num_heads=8,\n",
    "    num_layers=6,\n",
    "    max_len=128,\n",
    "    dropout_rate=0.1\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # Move model to device\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=en_tokenizer.pad_token_id)\n",
    "\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    \n",
    "    # Add BOS token for the decoder input\n",
    "    bos_tokens = torch.full((batch['decoder_input_ids'].shape[0], 1), \n",
    "                            en_tokenizer.bos_token_id, \n",
    "                            device=device)\n",
    "    decoder_in = torch.cat([bos_tokens, batch['decoder_input_ids']], dim=1)\n",
    "    \n",
    "    # Select up to second-last token for teacher forcing\n",
    "    decoder_in = decoder_in[:, :-1]\n",
    "\n",
    "    # Forward pass - shape: batch_size x seq_length x vocab_size\n",
    "    logits = model(batch[\"input_ids\"], decoder_in)\n",
    "\n",
    "    # Reshape for loss calculation. Loss_fn expects batch to be flattened\n",
    "    batch_size, seq_len, vocab_size = logits.shape\n",
    "    logits_reshaped = logits.contiguous().view(-1, vocab_size)\n",
    "    labels_reshaped = batch['labels'].contiguous().view(-1)\n",
    "\n",
    "    loss = loss_fn(logits_reshaped, labels_reshaped)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(f\"Batch {i}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91480892\n"
     ]
    }
   ],
   "source": [
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(31102, 512)\n",
      "    (pos_embedding): Embedding(128, 512)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (transformer_blocks): ModuleList(\n",
      "      (0-5): 6 x TransformerBlock(\n",
      "        (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (mha): MultiHeadAttention(\n",
      "          (Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (K): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (V): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (ffnn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(30524, 512)\n",
      "    (pos_embedding): Embedding(128, 512)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (decoder_blocks): ModuleList(\n",
      "      (0-5): 6 x DecoderBlock(\n",
      "        (attention_block): MultiHeadAttention(\n",
      "          (Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (K): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (V): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (w0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (transformer_block): TransformerBlock(\n",
      "          (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (mha): MultiHeadAttention(\n",
      "            (Q): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (K): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (V): Linear(in_features=512, out_features=512, bias=True)\n",
      "            (w0): Linear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (ffnn): Sequential(\n",
      "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
      "            (1): ReLU()\n",
      "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          )\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=30524, bias=True)\n",
      ")\n",
      "Total trainable parameters: 91,349,820\n",
      "encoder.embedding.weight: 15,924,224\n",
      "encoder.transformer_blocks.0.norm_1.weight: 512\n",
      "encoder.transformer_blocks.0.norm_1.bias: 512\n",
      "encoder.transformer_blocks.0.norm_2.weight: 512\n",
      "encoder.transformer_blocks.0.norm_2.bias: 512\n",
      "encoder.transformer_blocks.0.mha.Q.weight: 262,144\n",
      "encoder.transformer_blocks.0.mha.Q.bias: 512\n",
      "encoder.transformer_blocks.0.mha.K.weight: 262,144\n",
      "encoder.transformer_blocks.0.mha.K.bias: 512\n",
      "encoder.transformer_blocks.0.mha.V.weight: 262,144\n",
      "encoder.transformer_blocks.0.mha.V.bias: 512\n",
      "encoder.transformer_blocks.0.mha.w0.weight: 262,144\n",
      "encoder.transformer_blocks.0.mha.w0.bias: 512\n",
      "encoder.transformer_blocks.0.ffnn.0.weight: 1,048,576\n",
      "encoder.transformer_blocks.0.ffnn.0.bias: 2,048\n",
      "encoder.transformer_blocks.0.ffnn.2.weight: 1,048,576\n",
      "encoder.transformer_blocks.0.ffnn.2.bias: 512\n",
      "encoder.transformer_blocks.1.norm_1.weight: 512\n",
      "encoder.transformer_blocks.1.norm_1.bias: 512\n",
      "encoder.transformer_blocks.1.norm_2.weight: 512\n",
      "encoder.transformer_blocks.1.norm_2.bias: 512\n",
      "encoder.transformer_blocks.1.mha.Q.weight: 262,144\n",
      "encoder.transformer_blocks.1.mha.Q.bias: 512\n",
      "encoder.transformer_blocks.1.mha.K.weight: 262,144\n",
      "encoder.transformer_blocks.1.mha.K.bias: 512\n",
      "encoder.transformer_blocks.1.mha.V.weight: 262,144\n",
      "encoder.transformer_blocks.1.mha.V.bias: 512\n",
      "encoder.transformer_blocks.1.mha.w0.weight: 262,144\n",
      "encoder.transformer_blocks.1.mha.w0.bias: 512\n",
      "encoder.transformer_blocks.1.ffnn.0.weight: 1,048,576\n",
      "encoder.transformer_blocks.1.ffnn.0.bias: 2,048\n",
      "encoder.transformer_blocks.1.ffnn.2.weight: 1,048,576\n",
      "encoder.transformer_blocks.1.ffnn.2.bias: 512\n",
      "encoder.transformer_blocks.2.norm_1.weight: 512\n",
      "encoder.transformer_blocks.2.norm_1.bias: 512\n",
      "encoder.transformer_blocks.2.norm_2.weight: 512\n",
      "encoder.transformer_blocks.2.norm_2.bias: 512\n",
      "encoder.transformer_blocks.2.mha.Q.weight: 262,144\n",
      "encoder.transformer_blocks.2.mha.Q.bias: 512\n",
      "encoder.transformer_blocks.2.mha.K.weight: 262,144\n",
      "encoder.transformer_blocks.2.mha.K.bias: 512\n",
      "encoder.transformer_blocks.2.mha.V.weight: 262,144\n",
      "encoder.transformer_blocks.2.mha.V.bias: 512\n",
      "encoder.transformer_blocks.2.mha.w0.weight: 262,144\n",
      "encoder.transformer_blocks.2.mha.w0.bias: 512\n",
      "encoder.transformer_blocks.2.ffnn.0.weight: 1,048,576\n",
      "encoder.transformer_blocks.2.ffnn.0.bias: 2,048\n",
      "encoder.transformer_blocks.2.ffnn.2.weight: 1,048,576\n",
      "encoder.transformer_blocks.2.ffnn.2.bias: 512\n",
      "encoder.transformer_blocks.3.norm_1.weight: 512\n",
      "encoder.transformer_blocks.3.norm_1.bias: 512\n",
      "encoder.transformer_blocks.3.norm_2.weight: 512\n",
      "encoder.transformer_blocks.3.norm_2.bias: 512\n",
      "encoder.transformer_blocks.3.mha.Q.weight: 262,144\n",
      "encoder.transformer_blocks.3.mha.Q.bias: 512\n",
      "encoder.transformer_blocks.3.mha.K.weight: 262,144\n",
      "encoder.transformer_blocks.3.mha.K.bias: 512\n",
      "encoder.transformer_blocks.3.mha.V.weight: 262,144\n",
      "encoder.transformer_blocks.3.mha.V.bias: 512\n",
      "encoder.transformer_blocks.3.mha.w0.weight: 262,144\n",
      "encoder.transformer_blocks.3.mha.w0.bias: 512\n",
      "encoder.transformer_blocks.3.ffnn.0.weight: 1,048,576\n",
      "encoder.transformer_blocks.3.ffnn.0.bias: 2,048\n",
      "encoder.transformer_blocks.3.ffnn.2.weight: 1,048,576\n",
      "encoder.transformer_blocks.3.ffnn.2.bias: 512\n",
      "encoder.transformer_blocks.4.norm_1.weight: 512\n",
      "encoder.transformer_blocks.4.norm_1.bias: 512\n",
      "encoder.transformer_blocks.4.norm_2.weight: 512\n",
      "encoder.transformer_blocks.4.norm_2.bias: 512\n",
      "encoder.transformer_blocks.4.mha.Q.weight: 262,144\n",
      "encoder.transformer_blocks.4.mha.Q.bias: 512\n",
      "encoder.transformer_blocks.4.mha.K.weight: 262,144\n",
      "encoder.transformer_blocks.4.mha.K.bias: 512\n",
      "encoder.transformer_blocks.4.mha.V.weight: 262,144\n",
      "encoder.transformer_blocks.4.mha.V.bias: 512\n",
      "encoder.transformer_blocks.4.mha.w0.weight: 262,144\n",
      "encoder.transformer_blocks.4.mha.w0.bias: 512\n",
      "encoder.transformer_blocks.4.ffnn.0.weight: 1,048,576\n",
      "encoder.transformer_blocks.4.ffnn.0.bias: 2,048\n",
      "encoder.transformer_blocks.4.ffnn.2.weight: 1,048,576\n",
      "encoder.transformer_blocks.4.ffnn.2.bias: 512\n",
      "encoder.transformer_blocks.5.norm_1.weight: 512\n",
      "encoder.transformer_blocks.5.norm_1.bias: 512\n",
      "encoder.transformer_blocks.5.norm_2.weight: 512\n",
      "encoder.transformer_blocks.5.norm_2.bias: 512\n",
      "encoder.transformer_blocks.5.mha.Q.weight: 262,144\n",
      "encoder.transformer_blocks.5.mha.Q.bias: 512\n",
      "encoder.transformer_blocks.5.mha.K.weight: 262,144\n",
      "encoder.transformer_blocks.5.mha.K.bias: 512\n",
      "encoder.transformer_blocks.5.mha.V.weight: 262,144\n",
      "encoder.transformer_blocks.5.mha.V.bias: 512\n",
      "encoder.transformer_blocks.5.mha.w0.weight: 262,144\n",
      "encoder.transformer_blocks.5.mha.w0.bias: 512\n",
      "encoder.transformer_blocks.5.ffnn.0.weight: 1,048,576\n",
      "encoder.transformer_blocks.5.ffnn.0.bias: 2,048\n",
      "encoder.transformer_blocks.5.ffnn.2.weight: 1,048,576\n",
      "encoder.transformer_blocks.5.ffnn.2.bias: 512\n",
      "decoder.embedding.weight: 15,628,288\n",
      "decoder.decoder_blocks.0.attention_block.Q.weight: 262,144\n",
      "decoder.decoder_blocks.0.attention_block.Q.bias: 512\n",
      "decoder.decoder_blocks.0.attention_block.K.weight: 262,144\n",
      "decoder.decoder_blocks.0.attention_block.K.bias: 512\n",
      "decoder.decoder_blocks.0.attention_block.V.weight: 262,144\n",
      "decoder.decoder_blocks.0.attention_block.V.bias: 512\n",
      "decoder.decoder_blocks.0.attention_block.w0.weight: 262,144\n",
      "decoder.decoder_blocks.0.attention_block.w0.bias: 512\n",
      "decoder.decoder_blocks.0.transformer_block.norm_1.weight: 512\n",
      "decoder.decoder_blocks.0.transformer_block.norm_1.bias: 512\n",
      "decoder.decoder_blocks.0.transformer_block.norm_2.weight: 512\n",
      "decoder.decoder_blocks.0.transformer_block.norm_2.bias: 512\n",
      "decoder.decoder_blocks.0.transformer_block.mha.Q.weight: 262,144\n",
      "decoder.decoder_blocks.0.transformer_block.mha.Q.bias: 512\n",
      "decoder.decoder_blocks.0.transformer_block.mha.K.weight: 262,144\n",
      "decoder.decoder_blocks.0.transformer_block.mha.K.bias: 512\n",
      "decoder.decoder_blocks.0.transformer_block.mha.V.weight: 262,144\n",
      "decoder.decoder_blocks.0.transformer_block.mha.V.bias: 512\n",
      "decoder.decoder_blocks.0.transformer_block.mha.w0.weight: 262,144\n",
      "decoder.decoder_blocks.0.transformer_block.mha.w0.bias: 512\n",
      "decoder.decoder_blocks.0.transformer_block.ffnn.0.weight: 1,048,576\n",
      "decoder.decoder_blocks.0.transformer_block.ffnn.0.bias: 2,048\n",
      "decoder.decoder_blocks.0.transformer_block.ffnn.2.weight: 1,048,576\n",
      "decoder.decoder_blocks.0.transformer_block.ffnn.2.bias: 512\n",
      "decoder.decoder_blocks.0.norm.weight: 512\n",
      "decoder.decoder_blocks.0.norm.bias: 512\n",
      "decoder.decoder_blocks.1.attention_block.Q.weight: 262,144\n",
      "decoder.decoder_blocks.1.attention_block.Q.bias: 512\n",
      "decoder.decoder_blocks.1.attention_block.K.weight: 262,144\n",
      "decoder.decoder_blocks.1.attention_block.K.bias: 512\n",
      "decoder.decoder_blocks.1.attention_block.V.weight: 262,144\n",
      "decoder.decoder_blocks.1.attention_block.V.bias: 512\n",
      "decoder.decoder_blocks.1.attention_block.w0.weight: 262,144\n",
      "decoder.decoder_blocks.1.attention_block.w0.bias: 512\n",
      "decoder.decoder_blocks.1.transformer_block.norm_1.weight: 512\n",
      "decoder.decoder_blocks.1.transformer_block.norm_1.bias: 512\n",
      "decoder.decoder_blocks.1.transformer_block.norm_2.weight: 512\n",
      "decoder.decoder_blocks.1.transformer_block.norm_2.bias: 512\n",
      "decoder.decoder_blocks.1.transformer_block.mha.Q.weight: 262,144\n",
      "decoder.decoder_blocks.1.transformer_block.mha.Q.bias: 512\n",
      "decoder.decoder_blocks.1.transformer_block.mha.K.weight: 262,144\n",
      "decoder.decoder_blocks.1.transformer_block.mha.K.bias: 512\n",
      "decoder.decoder_blocks.1.transformer_block.mha.V.weight: 262,144\n",
      "decoder.decoder_blocks.1.transformer_block.mha.V.bias: 512\n",
      "decoder.decoder_blocks.1.transformer_block.mha.w0.weight: 262,144\n",
      "decoder.decoder_blocks.1.transformer_block.mha.w0.bias: 512\n",
      "decoder.decoder_blocks.1.transformer_block.ffnn.0.weight: 1,048,576\n",
      "decoder.decoder_blocks.1.transformer_block.ffnn.0.bias: 2,048\n",
      "decoder.decoder_blocks.1.transformer_block.ffnn.2.weight: 1,048,576\n",
      "decoder.decoder_blocks.1.transformer_block.ffnn.2.bias: 512\n",
      "decoder.decoder_blocks.1.norm.weight: 512\n",
      "decoder.decoder_blocks.1.norm.bias: 512\n",
      "decoder.decoder_blocks.2.attention_block.Q.weight: 262,144\n",
      "decoder.decoder_blocks.2.attention_block.Q.bias: 512\n",
      "decoder.decoder_blocks.2.attention_block.K.weight: 262,144\n",
      "decoder.decoder_blocks.2.attention_block.K.bias: 512\n",
      "decoder.decoder_blocks.2.attention_block.V.weight: 262,144\n",
      "decoder.decoder_blocks.2.attention_block.V.bias: 512\n",
      "decoder.decoder_blocks.2.attention_block.w0.weight: 262,144\n",
      "decoder.decoder_blocks.2.attention_block.w0.bias: 512\n",
      "decoder.decoder_blocks.2.transformer_block.norm_1.weight: 512\n",
      "decoder.decoder_blocks.2.transformer_block.norm_1.bias: 512\n",
      "decoder.decoder_blocks.2.transformer_block.norm_2.weight: 512\n",
      "decoder.decoder_blocks.2.transformer_block.norm_2.bias: 512\n",
      "decoder.decoder_blocks.2.transformer_block.mha.Q.weight: 262,144\n",
      "decoder.decoder_blocks.2.transformer_block.mha.Q.bias: 512\n",
      "decoder.decoder_blocks.2.transformer_block.mha.K.weight: 262,144\n",
      "decoder.decoder_blocks.2.transformer_block.mha.K.bias: 512\n",
      "decoder.decoder_blocks.2.transformer_block.mha.V.weight: 262,144\n",
      "decoder.decoder_blocks.2.transformer_block.mha.V.bias: 512\n",
      "decoder.decoder_blocks.2.transformer_block.mha.w0.weight: 262,144\n",
      "decoder.decoder_blocks.2.transformer_block.mha.w0.bias: 512\n",
      "decoder.decoder_blocks.2.transformer_block.ffnn.0.weight: 1,048,576\n",
      "decoder.decoder_blocks.2.transformer_block.ffnn.0.bias: 2,048\n",
      "decoder.decoder_blocks.2.transformer_block.ffnn.2.weight: 1,048,576\n",
      "decoder.decoder_blocks.2.transformer_block.ffnn.2.bias: 512\n",
      "decoder.decoder_blocks.2.norm.weight: 512\n",
      "decoder.decoder_blocks.2.norm.bias: 512\n",
      "decoder.decoder_blocks.3.attention_block.Q.weight: 262,144\n",
      "decoder.decoder_blocks.3.attention_block.Q.bias: 512\n",
      "decoder.decoder_blocks.3.attention_block.K.weight: 262,144\n",
      "decoder.decoder_blocks.3.attention_block.K.bias: 512\n",
      "decoder.decoder_blocks.3.attention_block.V.weight: 262,144\n",
      "decoder.decoder_blocks.3.attention_block.V.bias: 512\n",
      "decoder.decoder_blocks.3.attention_block.w0.weight: 262,144\n",
      "decoder.decoder_blocks.3.attention_block.w0.bias: 512\n",
      "decoder.decoder_blocks.3.transformer_block.norm_1.weight: 512\n",
      "decoder.decoder_blocks.3.transformer_block.norm_1.bias: 512\n",
      "decoder.decoder_blocks.3.transformer_block.norm_2.weight: 512\n",
      "decoder.decoder_blocks.3.transformer_block.norm_2.bias: 512\n",
      "decoder.decoder_blocks.3.transformer_block.mha.Q.weight: 262,144\n",
      "decoder.decoder_blocks.3.transformer_block.mha.Q.bias: 512\n",
      "decoder.decoder_blocks.3.transformer_block.mha.K.weight: 262,144\n",
      "decoder.decoder_blocks.3.transformer_block.mha.K.bias: 512\n",
      "decoder.decoder_blocks.3.transformer_block.mha.V.weight: 262,144\n",
      "decoder.decoder_blocks.3.transformer_block.mha.V.bias: 512\n",
      "decoder.decoder_blocks.3.transformer_block.mha.w0.weight: 262,144\n",
      "decoder.decoder_blocks.3.transformer_block.mha.w0.bias: 512\n",
      "decoder.decoder_blocks.3.transformer_block.ffnn.0.weight: 1,048,576\n",
      "decoder.decoder_blocks.3.transformer_block.ffnn.0.bias: 2,048\n",
      "decoder.decoder_blocks.3.transformer_block.ffnn.2.weight: 1,048,576\n",
      "decoder.decoder_blocks.3.transformer_block.ffnn.2.bias: 512\n",
      "decoder.decoder_blocks.3.norm.weight: 512\n",
      "decoder.decoder_blocks.3.norm.bias: 512\n",
      "decoder.decoder_blocks.4.attention_block.Q.weight: 262,144\n",
      "decoder.decoder_blocks.4.attention_block.Q.bias: 512\n",
      "decoder.decoder_blocks.4.attention_block.K.weight: 262,144\n",
      "decoder.decoder_blocks.4.attention_block.K.bias: 512\n",
      "decoder.decoder_blocks.4.attention_block.V.weight: 262,144\n",
      "decoder.decoder_blocks.4.attention_block.V.bias: 512\n",
      "decoder.decoder_blocks.4.attention_block.w0.weight: 262,144\n",
      "decoder.decoder_blocks.4.attention_block.w0.bias: 512\n",
      "decoder.decoder_blocks.4.transformer_block.norm_1.weight: 512\n",
      "decoder.decoder_blocks.4.transformer_block.norm_1.bias: 512\n",
      "decoder.decoder_blocks.4.transformer_block.norm_2.weight: 512\n",
      "decoder.decoder_blocks.4.transformer_block.norm_2.bias: 512\n",
      "decoder.decoder_blocks.4.transformer_block.mha.Q.weight: 262,144\n",
      "decoder.decoder_blocks.4.transformer_block.mha.Q.bias: 512\n",
      "decoder.decoder_blocks.4.transformer_block.mha.K.weight: 262,144\n",
      "decoder.decoder_blocks.4.transformer_block.mha.K.bias: 512\n",
      "decoder.decoder_blocks.4.transformer_block.mha.V.weight: 262,144\n",
      "decoder.decoder_blocks.4.transformer_block.mha.V.bias: 512\n",
      "decoder.decoder_blocks.4.transformer_block.mha.w0.weight: 262,144\n",
      "decoder.decoder_blocks.4.transformer_block.mha.w0.bias: 512\n",
      "decoder.decoder_blocks.4.transformer_block.ffnn.0.weight: 1,048,576\n",
      "decoder.decoder_blocks.4.transformer_block.ffnn.0.bias: 2,048\n",
      "decoder.decoder_blocks.4.transformer_block.ffnn.2.weight: 1,048,576\n",
      "decoder.decoder_blocks.4.transformer_block.ffnn.2.bias: 512\n",
      "decoder.decoder_blocks.4.norm.weight: 512\n",
      "decoder.decoder_blocks.4.norm.bias: 512\n",
      "decoder.decoder_blocks.5.attention_block.Q.weight: 262,144\n",
      "decoder.decoder_blocks.5.attention_block.Q.bias: 512\n",
      "decoder.decoder_blocks.5.attention_block.K.weight: 262,144\n",
      "decoder.decoder_blocks.5.attention_block.K.bias: 512\n",
      "decoder.decoder_blocks.5.attention_block.V.weight: 262,144\n",
      "decoder.decoder_blocks.5.attention_block.V.bias: 512\n",
      "decoder.decoder_blocks.5.attention_block.w0.weight: 262,144\n",
      "decoder.decoder_blocks.5.attention_block.w0.bias: 512\n",
      "decoder.decoder_blocks.5.transformer_block.norm_1.weight: 512\n",
      "decoder.decoder_blocks.5.transformer_block.norm_1.bias: 512\n",
      "decoder.decoder_blocks.5.transformer_block.norm_2.weight: 512\n",
      "decoder.decoder_blocks.5.transformer_block.norm_2.bias: 512\n",
      "decoder.decoder_blocks.5.transformer_block.mha.Q.weight: 262,144\n",
      "decoder.decoder_blocks.5.transformer_block.mha.Q.bias: 512\n",
      "decoder.decoder_blocks.5.transformer_block.mha.K.weight: 262,144\n",
      "decoder.decoder_blocks.5.transformer_block.mha.K.bias: 512\n",
      "decoder.decoder_blocks.5.transformer_block.mha.V.weight: 262,144\n",
      "decoder.decoder_blocks.5.transformer_block.mha.V.bias: 512\n",
      "decoder.decoder_blocks.5.transformer_block.mha.w0.weight: 262,144\n",
      "decoder.decoder_blocks.5.transformer_block.mha.w0.bias: 512\n",
      "decoder.decoder_blocks.5.transformer_block.ffnn.0.weight: 1,048,576\n",
      "decoder.decoder_blocks.5.transformer_block.ffnn.0.bias: 2,048\n",
      "decoder.decoder_blocks.5.transformer_block.ffnn.2.weight: 1,048,576\n",
      "decoder.decoder_blocks.5.transformer_block.ffnn.2.bias: 512\n",
      "decoder.decoder_blocks.5.norm.weight: 512\n",
      "decoder.decoder_blocks.5.norm.bias: 512\n",
      "linear.weight: 15,628,288\n",
      "linear.bias: 30,524\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Print model architecture\n",
    "print(model)\n",
    "\n",
    "# Print total parameter count\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Total trainable parameters: {total_params:,}\")\n",
    "\n",
    "# Print parameter count for each layer/module\n",
    "for name, parameter in model.named_parameters():\n",
    "    if parameter.requires_grad:\n",
    "        print(f\"{name}: {parameter.numel():,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
